{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Lz6xp7-toKO",
        "outputId": "ea1b269a-b08b-4d9c-d661-10e5f48c3c95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-03 21:44:26--  http://www.mpi-sws.org/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
            "Resolving www.mpi-sws.org (www.mpi-sws.org)... 139.19.205.208\n",
            "Connecting to www.mpi-sws.org (www.mpi-sws.org)|139.19.205.208|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.mpi-sws.org/~cristian/data/cornell_movie_dialogs_corpus.zip [following]\n",
            "--2022-09-03 21:44:27--  https://www.mpi-sws.org/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
            "Connecting to www.mpi-sws.org (www.mpi-sws.org)|139.19.205.208|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://people.mpi-sws.org/~cristian/data/cornell_movie_dialogs_corpus.zip [following]\n",
            "--2022-09-03 21:44:27--  https://people.mpi-sws.org/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
            "Resolving people.mpi-sws.org (people.mpi-sws.org)... 139.19.206.131\n",
            "Connecting to people.mpi-sws.org (people.mpi-sws.org)|139.19.206.131|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip [following]\n",
            "--2022-09-03 21:44:28--  http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
            "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.36\n",
            "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.36|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9916637 (9.5M) [application/zip]\n",
            "Saving to: ‘cornell_movie_dialogs_corpus.zip.1’\n",
            "\n",
            "cornell_movie_dialo 100%[===================>]   9.46M  24.9MB/s    in 0.4s    \n",
            "\n",
            "2022-09-03 21:44:29 (24.9 MB/s) - ‘cornell_movie_dialogs_corpus.zip.1’ saved [9916637/9916637]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://www.mpi-sws.org/~cristian/data/cornell_movie_dialogs_corpus.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/cornell_movie_dialogs_corpus.zip\" -d \"cornell_movie_dialogs_corpus/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHlt-zLTvpyh",
        "outputId": "772d58e5-65eb-4edd-eef1-6d99bca29c93"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/cornell_movie_dialogs_corpus.zip\n",
            "replace cornell_movie_dialogs_corpus/cornell movie-dialogs corpus/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: غ\n",
            "error:  invalid response [غ]\n",
            "replace cornell_movie_dialogs_corpus/cornell movie-dialogs corpus/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: cornell_movie_dialogs_corpus/cornell movie-dialogs corpus/.DS_Store  \n",
            "replace cornell_movie_dialogs_corpus/__MACOSX/cornell movie-dialogs corpus/._.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: cornell_movie_dialogs_corpus/__MACOSX/cornell movie-dialogs corpus/._.DS_Store  \n",
            "replace cornell_movie_dialogs_corpus/cornell movie-dialogs corpus/chameleons.pdf? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: cornell_movie_dialogs_corpus/cornell movie-dialogs corpus/chameleons.pdf  \n",
            "replace cornell_movie_dialogs_corpus/__MACOSX/cornell movie-dialogs corpus/._chameleons.pdf? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: cornell_movie_dialogs_corpus/__MACOSX/cornell movie-dialogs corpus/._chameleons.pdf  \n",
            "replace cornell_movie_dialogs_corpus/cornell movie-dialogs corpus/movie_characters_metadata.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: cornell_movie_dialogs_corpus/cornell movie-dialogs corpus/movie_characters_metadata.txt  \n",
            "replace cornell_movie_dialogs_corpus/cornell movie-dialogs corpus/movie_conversations.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: cornell_movie_dialogs_corpus/cornell movie-dialogs corpus/movie_conversations.txt  \n",
            "replace cornell_movie_dialogs_corpus/cornell movie-dialogs corpus/movie_lines.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: cornell_movie_dialogs_corpus/cornell movie-dialogs corpus/movie_lines.txt  \n",
            "  inflating: cornell_movie_dialogs_corpus/cornell movie-dialogs corpus/movie_titles_metadata.txt  \n",
            "  inflating: cornell_movie_dialogs_corpus/cornell movie-dialogs corpus/raw_script_urls.txt  \n",
            "  inflating: cornell_movie_dialogs_corpus/cornell movie-dialogs corpus/README.txt  \n",
            "  inflating: cornell_movie_dialogs_corpus/__MACOSX/cornell movie-dialogs corpus/._README.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re"
      ],
      "metadata": {
        "id": "Bsk9ig-sv909"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFkWTU9xFiBT",
        "outputId": "64785f2b-9e29-46ea-bd94-ec3b7afb4f5f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines = open(\"/content/cornell_movie_dialogs_corpus/cornell movie-dialogs corpus/movie_lines.txt\", encoding=\"utf-8\", errors=\"ignore\")\n",
        "lines = lines.read().split('\\n')\n",
        "\n",
        "conv_lines = open(\"/content/cornell_movie_dialogs_corpus/cornell movie-dialogs corpus/movie_conversations.txt\", encoding=\"utf-8\", errors=\"ignore\")\n",
        "conv_lines = conv_lines.read().split(\"\\n\")"
      ],
      "metadata": {
        "id": "VqMD9UYcwrMq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2line = {}\n",
        "for line in lines:\n",
        "  _line = line.split(\" +++$+++ \")\n",
        "  if len(_line) == 5:\n",
        "    id2line[_line[0]] = _line[4]"
      ],
      "metadata": {
        "id": "d-dlBP4gxPtJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convs = []\n",
        "for line in conv_lines[:-1]:\n",
        "    _line = line.split(\" +++$+++ \")[-1][1:-1]\n",
        "    _line = _line.replace(\"'\",\"\").replace(\" \",\"\")\n",
        "    convs.append(_line.split(','))"
      ],
      "metadata": {
        "id": "3tVsPv3GyDyt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in convs[0]:\n",
        "  print(k, id2line[k])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjPPFwZjye1-",
        "outputId": "9940e289-6a0b-46e3-a3b5-eaf37008b237"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L194 Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\n",
            "L195 Well, I thought we'd start with pronunciation, if that's okay with you.\n",
            "L196 Not the hacking and gagging and spitting part.  Please.\n",
            "L197 Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "questions = []\n",
        "answers = []\n",
        "for conv in convs:\n",
        "  for i in range(len(conv)-1):\n",
        "    questions.append(id2line[conv[i]])\n",
        "    answers.append(id2line[conv[i+1]])\n",
        "\n",
        "print(len(questions))\n",
        "print(len(answers))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSnleO9Oy5Ak",
        "outputId": "5b8b1d1d-1e6d-48b2-e22b-67a0185b6f58"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "221616\n",
            "221616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "  text = text.lower()\n",
        "  text = re.sub(r\"i'm\", \"i am\", text)\n",
        "  text = re.sub(r\"he's\", \"he is\", text)\n",
        "  text = re.sub(r\"she's\", \"she is\", text)\n",
        "  text = re.sub(r\"it's\", \"it is\", text)\n",
        "  text = re.sub(r\"that's\", \"that is\", text)\n",
        "  text = re.sub(r\"what's\", \"that is\", text)\n",
        "  text = re.sub(r\"where's\", \"where is\", text)\n",
        "  text = re.sub(r\"how's\", \"how is\", text)\n",
        "  text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "  text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "  text = re.sub(r\"\\'re\", \" are\", text)\n",
        "  text = re.sub(r\"\\'d\", \" would\", text)\n",
        "  text = re.sub(r\"\\'re\", \" are\", text)\n",
        "  text = re.sub(r\"won't\", \"will not\", text)\n",
        "  text = re.sub(r\"can't\", \"cannot\", text)\n",
        "  text = re.sub(r\"n't\", \" not\", text)\n",
        "  text = re.sub(r\"n'\", \"ng\", text)\n",
        "  text = re.sub(r\"'bout\", \"about\", text)\n",
        "  text = re.sub(r\"'til\", \"until\", text)\n",
        "  text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
        "  text = \" \".join(text.split())\n",
        "  return text"
      ],
      "metadata": {
        "id": "l8Jp6rV2zotU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_questions = []\n",
        "for question in questions:\n",
        "  clean_questions.append(clean_text(question))"
      ],
      "metadata": {
        "id": "G3SLTjvW5dfc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_answers = []\n",
        "for answer in answers:\n",
        "  clean_answers.append(clean_text(answer))"
      ],
      "metadata": {
        "id": "5GNgJMIc5xxW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lengths = []\n",
        "for question in clean_questions:\n",
        "  lengths.append(len(question.split()))\n",
        "\n",
        "for answer in clean_answers:\n",
        "  lengths.append(len(answer.split()))\n",
        "\n",
        "lengths = pd.DataFrame(lengths, columns=[\"text length\"])\n",
        "print(np.percentile(lengths, 80))\n",
        "print(np.percentile(lengths, 85))\n",
        "print(np.percentile(lengths, 90))\n",
        "print(np.percentile(lengths, 95))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NFQqFox5yww",
        "outputId": "f9e2b645-d250-4007-d69d-7156ce17fbbe"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16.0\n",
            "19.0\n",
            "24.0\n",
            "32.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min_line_length = 2\n",
        "max_line_length = 20\n",
        "\n",
        "short_questions_temp = []\n",
        "short_answers_temp = []\n",
        "\n",
        "for i, question  in enumerate(clean_questions):\n",
        "  if len(question.split()) >= min_line_length and len(question.split()) <= max_line_length:\n",
        "    short_questions_temp.append(question)\n",
        "    short_answers_temp.append(clean_answers[i])"
      ],
      "metadata": {
        "id": "M2XWmtVQB0v_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "short_questions = []\n",
        "short_answers = []\n",
        "\n",
        "for i, answer in enumerate(short_answers_temp):\n",
        "  if len(answer.split()) >= min_line_length and len(answer.split()) <= max_line_length:\n",
        "    short_answers.append(answer)\n",
        "    short_questions.append(short_questions_temp[i])\n",
        "\n",
        "print(len(short_questions))\n",
        "print(len(short_answers))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmU_HkenDAIm",
        "outputId": "d02513bd-8445-44f7-99d4-25dc9d4b4491"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "138335\n",
            "138335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rand = np.random.randint(1, len(short_questions))\n",
        "\n",
        "for i in range(rand, rand+3):\n",
        "  print(short_questions[i])\n",
        "  print(short_answers[i])\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3dCTItmDmd0",
        "outputId": "5fd1173f-3414-4e65-bda2-819c664ab00f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i knew his greatgrandfather\n",
            "you are insane\n",
            "\n",
            "you are insane\n",
            "no seriously we used to shoot pool together in rangoon\n",
            "\n",
            "no seriously we used to shoot pool together in rangoon\n",
            "how do you do it kahn how do you live so full of life for so long\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 30000\n",
        "short_questions = short_questions[:num_samples]\n",
        "short_answers = short_answers[:num_samples]\n"
      ],
      "metadata": {
        "id": "dWHgFexCD4zy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "short_questions_token = [nltk.word_tokenize(sent) for sent in short_questions]\n",
        "\n",
        "short_answers_token = [nltk.word_tokenize(sent) for sent in short_answers]"
      ],
      "metadata": {
        "id": "7XEruGGmFRjC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_size = len(short_questions_token)\n",
        "\n",
        "training_input = short_questions_token[:round(data_size*0.8)]\n",
        "training_input = [tr_input[::-1] for tr_input in training_input]\n",
        "training_output = short_answers_token[:round(data_size*0.8)]"
      ],
      "metadata": {
        "id": "1szFsUn9Ffez"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_input = short_questions_token[round(data_size*(80/100)):]\n",
        "validation_input  = [val_input[::-1] for val_input in validation_input] #reverseing input seq for better performance\n",
        "validation_output = short_questions_token[round(data_size*(80/100)):]"
      ],
      "metadata": {
        "id": "ocRV7sEbGyzZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('training size', len(training_input))\n",
        "print('validation size', len(validation_input))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRQgvaY6Hn9A",
        "outputId": "a70f7ebd-69cf-480d-b1ad-fc70e73e5741"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training size 24000\n",
            "validation size 6000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {}\n",
        "\n",
        "for question in short_questions_token:\n",
        "  for word in question:\n",
        "    if word not in vocab:\n",
        "      vocab[word] = 1\n",
        "    else:\n",
        "      vocab[word] += 1\n",
        "\n",
        "for answer in short_answers_token:\n",
        "  for word in answer:\n",
        "    if word not in vocab:\n",
        "      vocab[word] = 1\n",
        "    else:\n",
        "      vocab[word] += 1"
      ],
      "metadata": {
        "id": "1hog2QrxHpzP"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 15\n",
        "count = 0\n",
        "\n",
        "for k, v in vocab.items():\n",
        "  if v >= threshold:\n",
        "    count += 1"
      ],
      "metadata": {
        "id": "YaECMUrQIeuK"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Size of total vocab:\", len(vocab))\n",
        "print(\"Size of vocab we will use:\", count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xl-xD0dYIqvy",
        "outputId": "576d9ef5-0dee-4a1d-a890-2845c84d9b90"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of total vocab: 16655\n",
            "Size of vocab we will use: 1935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WORD_CODE_START = 1\n",
        "WORD_CODE_PADDING = 0\n",
        "\n",
        "word_num = 2\n",
        "\n",
        "encoding = {}\n",
        "decoding = {1: \"START\"}\n",
        "\n",
        "for word, count in vocab.items():\n",
        "  if count >= threshold:\n",
        "    encoding[word] = word_num\n",
        "    decoding[word_num] = word\n",
        "    word_num += 1\n",
        "\n",
        "print(\"No. of vocab used:\", word_num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OB96FvsXItRe",
        "outputId": "898eba05-7cfb-4910-d4d8-c9124683adff"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of vocab used: 1937\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoding[len(encoding)+2] = '<UNK>'\n",
        "encoding['<UNK>'] = len(encoding)+2"
      ],
      "metadata": {
        "id": "zO6BbcU2J7Qs"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_size = word_num+1\n",
        "dict_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qIDrVjBKKcJ",
        "outputId": "f968442d-529a-46f8-c9d7-cd40f28558fe"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1938"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transform(encoding, data, vector_size=20):\n",
        "  transformed_data = np.zeros(shape=(len(data), vector_size))\n",
        "  for i in range(len(data)):\n",
        "    for j in range(min(len(data[i]), vector_size)):\n",
        "      try:\n",
        "        transformed_data[i][j] = encoding[data[i][j]]\n",
        "      except:\n",
        "        transformed_data[i][j] = encoding[\"<UNK>\"]\n",
        "\n",
        "  return transformed_data"
      ],
      "metadata": {
        "id": "rfNGCDlXKL4s"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_LENGTH = 20\n",
        "OUTPUT_LENGTH = 20\n",
        "\n",
        "encoded_training_input = transform(encoding, training_input, \n",
        "                                   vector_size=INPUT_LENGTH)\n",
        "\n",
        "encoded_training_output = transform(encoding, training_input, \n",
        "                                   vector_size=OUTPUT_LENGTH)\n",
        "\n",
        "print('encoded_training_input', encoded_training_input.shape)\n",
        "print('encoded_training_output', encoded_training_output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SluXdLfeLAUr",
        "outputId": "5b8980a5-b31b-4898-81cd-fd8e88786f85"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoded_training_input (24000, 20)\n",
            "encoded_training_output (24000, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_validation_input = transform(\n",
        "    encoding, validation_input, vector_size=INPUT_LENGTH)\n",
        "encoded_validation_output = transform(\n",
        "    encoding, validation_output, vector_size=OUTPUT_LENGTH)\n",
        "\n",
        "print('encoded_validation_input', encoded_validation_input.shape)\n",
        "print('encoded_validation_output', encoded_validation_output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GIBsVGLNNv9",
        "outputId": "5f551001-ce86-4886-e83a-d1d33e9a9c65"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoded_validation_input (6000, 20)\n",
            "encoded_validation_output (6000, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "f09PHeCRNfvX"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Embedding, LSTM, TimeDistributed, Dense, Bidirectional\n",
        "from keras.layers import Activation, dot, concatenate\n",
        "from keras.models import Model, load_model"
      ],
      "metadata": {
        "id": "Ww3YdnfjNu5f"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = Input(shape=(INPUT_LENGTH,))\n",
        "decoder_input = Input(shape=(OUTPUT_LENGTH,))"
      ],
      "metadata": {
        "id": "YTnTTfedNoNj"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Embedding(dict_size, 128, input_length=INPUT_LENGTH, mask_zero=True)(encoder_input)\n",
        "encoder = LSTM(512, return_sequences=True, unroll=True)(encoder)\n",
        "encoder_last = encoder[:,-1,:]\n",
        "\n",
        "print(\"encoder\", encoder)\n",
        "print(\"encoder_last\", encoder_last)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdO3TTJONxup",
        "outputId": "0ed96fed-dbd8-440f-c57d-b177c2f4e069"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder KerasTensor(type_spec=TensorSpec(shape=(None, 20, 512), dtype=tf.float32, name=None), name='lstm/transpose_2:0', description=\"created by layer 'lstm'\")\n",
            "encoder_last KerasTensor(type_spec=TensorSpec(shape=(None, 512), dtype=tf.float32, name=None), name='tf.__operators__.getitem/strided_slice:0', description=\"created by layer 'tf.__operators__.getitem'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Embedding(dict_size, 128, input_length=OUTPUT_LENGTH, mask_zero=True)(decoder_input)\n",
        "decoder = LSTM(512, return_sequences=True, unroll=True)(decoder, initial_state=[encoder_last, encoder_last])\n",
        "print('decoder', decoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2gv5JJvOqS7",
        "outputId": "75aed65e-b8d0-4346-f11e-2f39999577b9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decoder KerasTensor(type_spec=TensorSpec(shape=(None, 20, 512), dtype=tf.float32, name=None), name='lstm_1/transpose_2:0', description=\"created by layer 'lstm_1'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention = dot([decoder, encoder], axes=[2,2])\n",
        "attention = Activation(\"softmax\", name=\"attention\")(attention)\n",
        "print('attention', attention)\n",
        "\n",
        "context = dot([attention, encoder], axes=[2,1])\n",
        "print('context', context)\n",
        "\n",
        "decoder_combined_context = concatenate([context, decoder])\n",
        "print('decoder_combined_context', decoder_combined_context)\n",
        "\n",
        "output = TimeDistributed(Dense(512, activation=\"tanh\"))(decoder_combined_context)\n",
        "output = TimeDistributed(Dense(dict_size, activation=\"softmax\"))(output)\n",
        "print(\"output\", output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSPtgSRiPnxa",
        "outputId": "b0bc618d-1f27-49e7-a2c0-279a3a58983c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attention KerasTensor(type_spec=TensorSpec(shape=(None, 20, 20), dtype=tf.float32, name=None), name='attention/Softmax:0', description=\"created by layer 'attention'\")\n",
            "context KerasTensor(type_spec=TensorSpec(shape=(None, 20, 512), dtype=tf.float32, name=None), name='dot_1/MatMul:0', description=\"created by layer 'dot_1'\")\n",
            "decoder_combined_context KerasTensor(type_spec=TensorSpec(shape=(None, 20, 1024), dtype=tf.float32, name=None), name='concatenate/concat:0', description=\"created by layer 'concatenate'\")\n",
            "output KerasTensor(type_spec=TensorSpec(shape=(None, 20, 1938), dtype=tf.float32, name=None), name='time_distributed_1/Reshape_1:0', description=\"created by layer 'time_distributed_1'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=[encoder_input, decoder_input], outputs=[output])\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkRvAecsPLZQ",
        "outputId": "c905f1f6-a27f-49bf-b2c3-2350549f1cbe"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 20)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 20, 128)      248064      ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 20)]         0           []                               \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 20, 512)      1312768     ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 20, 128)      248064      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 512)         0           ['lstm[0][0]']                   \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  (None, 20, 512)      1312768     ['embedding_1[0][0]',            \n",
            "                                                                  'tf.__operators__.getitem[0][0]'\n",
            "                                                                 , 'tf.__operators__.getitem[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " dot (Dot)                      (None, 20, 20)       0           ['lstm_1[0][0]',                 \n",
            "                                                                  'lstm[0][0]']                   \n",
            "                                                                                                  \n",
            " attention (Activation)         (None, 20, 20)       0           ['dot[0][0]']                    \n",
            "                                                                                                  \n",
            " dot_1 (Dot)                    (None, 20, 512)      0           ['attention[0][0]',              \n",
            "                                                                  'lstm[0][0]']                   \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 20, 1024)     0           ['dot_1[0][0]',                  \n",
            "                                                                  'lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            " time_distributed (TimeDistribu  (None, 20, 512)     524800      ['concatenate[0][0]']            \n",
            " ted)                                                                                             \n",
            "                                                                                                  \n",
            " time_distributed_1 (TimeDistri  (None, 20, 1938)    994194      ['time_distributed[0][0]']       \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,640,658\n",
            "Trainable params: 4,640,658\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_encoder_input = encoded_training_input\n",
        "training_decoder_input = np.zeros_like(encoded_training_output)\n",
        "\n",
        "training_decoder_input[:, 1:] = encoded_training_output[:, :-1]\n",
        "training_decoder_input[:, 0] = WORD_CODE_START\n",
        "\n",
        "training_decoder_output = np.eye(dict_size)[encoded_training_output.astype(\"int\")]"
      ],
      "metadata": {
        "id": "5CVmCnxvRmOb"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_encoder_input = encoded_validation_input\n",
        "validation_decoder_input = np.zeros_like(encoded_validation_output)\n",
        "\n",
        "validation_decoder_input[:, 1:] = encoded_validation_output[:, :-1]\n",
        "validation_decoder_input[:, 0] = WORD_CODE_START\n",
        "\n",
        "validation_decoder_output = np.eye(dict_size)[encoded_validation_output.astype(\"int\")]"
      ],
      "metadata": {
        "id": "yjLWW03rSRyo"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=[training_encoder_input, training_decoder_input], \n",
        "          y=[training_decoder_output],\n",
        "          validation_data=([validation_encoder_input, validation_decoder_input], \n",
        "                           [validation_decoder_output]),\n",
        "          batch_size=64,\n",
        "          epochs=100)\n",
        "\n",
        "model.save(\"model_attention.h5\")"
      ],
      "metadata": {
        "id": "bI3dKFctSg2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(raw_input):\n",
        "    clean_input = clean_text(raw_input)\n",
        "    input_tok = [nltk.word_tokenize(clean_input)]\n",
        "    input_tok = [input_tok[0][::-1]]  \n",
        "    encoder_input = transform(encoding, input_tok, 20)\n",
        "    decoder_input = np.zeros(shape=(len(encoder_input), OUTPUT_LENGTH))\n",
        "    decoder_input[:,0] = WORD_CODE_START\n",
        "    for i in range(1, OUTPUT_LENGTH):\n",
        "        output = model.predict([encoder_input, decoder_input]).argmax(axis=2)\n",
        "        decoder_input[:,i] = output[:,i]\n",
        "    return output"
      ],
      "metadata": {
        "id": "sytGaWfTTAw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(decoding, vector):\n",
        "    text = ''\n",
        "    for i in vector:\n",
        "        if i == 0:\n",
        "            break\n",
        "        text += ' '\n",
        "        text += decoding[i]\n",
        "    return text"
      ],
      "metadata": {
        "id": "IWX2lvKtUXLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "    seq_index = np.random.randint(1, len(short_questions))\n",
        "    output = prediction(short_questions[seq_index])\n",
        "    print ('Q:', short_questions[seq_index])\n",
        "    print ('A:', decode(decoding, output[0]))"
      ],
      "metadata": {
        "id": "j-6zrHj9Ubbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_input = input()\n",
        "output = prediction(raw_input)\n",
        "print (decode(decoding, output[0]))"
      ],
      "metadata": {
        "id": "AEo3_NKLUf7f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}