{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Yolo5ObjectTrackingAndClassification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQYEZOnSDzsg"
      },
      "outputs": [],
      "source": [
        "#!pip install yolov5\n",
        "# !pip install norfair "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget https://motchallenge.net/sequenceVideos/MOT17-04-DPM-raw.webm"
      ],
      "metadata": {
        "id": "LG87HnL5vPlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!ffmpeg -i MOT17-04-DPM-raw.webm MOT17-04-DPM-raw.mp4"
      ],
      "metadata": {
        "id": "876fu4zTvoQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from norfair.drawing import draw_boxes\n",
        "import argparse\n",
        "from typing import List, Optional, Union\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.ops.boxes as bops\n",
        "import yolov5\n",
        "\n",
        "import norfair\n",
        "from norfair import Detection, Tracker, Video, Paths\n",
        "\n",
        "DISTANCE_THRESHOLD_BBOX: float = 3.33\n",
        "DISTANCE_THRESHOLD_CENTROID: int = 30\n",
        "MAX_DISTANCE: int = 10000\n",
        "\n",
        "\n",
        "class YOLO:\n",
        "    def __init__(self, model_path: str, device: Optional[str] = None):\n",
        "        if device is not None and \"cuda\" in device and not torch.cuda.is_available():\n",
        "            raise Exception(\n",
        "                \"Selected device='cuda', but cuda is not available to Pytorch.\"\n",
        "            )\n",
        "        # automatically set device if its None\n",
        "        elif device is None:\n",
        "            device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "        # load model\n",
        "        self.model = yolov5.load(model_path, device=device)\n",
        "\n",
        "    def __call__(\n",
        "        self,\n",
        "        img: Union[str, np.ndarray],\n",
        "        conf_threshold: float = 0.25,\n",
        "        iou_threshold: float = 0.45,\n",
        "        image_size: int = 720,\n",
        "        classes: Optional[List[int]] = None\n",
        "    ) -> torch.tensor:\n",
        "\n",
        "        self.model.conf = conf_threshold\n",
        "        self.model.iou = iou_threshold\n",
        "        if classes is not None:\n",
        "            self.model.classes = classes\n",
        "        detections = self.model(img, size=image_size)\n",
        "        return detections\n",
        "\n",
        "\n",
        "def euclidean_distance(detection, tracked_object):\n",
        "    return np.linalg.norm(detection.points - tracked_object.estimate)\n",
        "\n",
        "\n",
        "def center(points):\n",
        "    return [np.mean(np.array(points), axis=0)]\n",
        "\n",
        "\n",
        "def iou_pytorch(detection, tracked_object):\n",
        "    # Slower but simplier version of iou\n",
        "\n",
        "    detection_points = np.concatenate([detection.points[0], detection.points[1]])\n",
        "    tracked_object_points = np.concatenate(\n",
        "        [tracked_object.estimate[0], tracked_object.estimate[1]]\n",
        "    )\n",
        "\n",
        "    box_a = torch.tensor([detection_points], dtype=torch.float)\n",
        "    box_b = torch.tensor([tracked_object_points], dtype=torch.float)\n",
        "    iou = bops.box_iou(box_a, box_b)\n",
        "\n",
        "    # Since 0 <= IoU <= 1, we define 1/IoU as a distance.\n",
        "    # Distance values will be in [1, inf)\n",
        "    return np.float(1 / iou if iou else MAX_DISTANCE)\n",
        "\n",
        "\n",
        "def iou(detection, tracked_object):\n",
        "    # Detection points will be box A\n",
        "    # Tracked objects point will be box B.\n",
        "\n",
        "    box_a = np.concatenate([detection.points[0], detection.points[1]])\n",
        "    box_b = np.concatenate([tracked_object.estimate[0], tracked_object.estimate[1]])\n",
        "\n",
        "    x_a = max(box_a[0], box_b[0])\n",
        "    y_a = max(box_a[1], box_b[1])\n",
        "    x_b = min(box_a[2], box_b[2])\n",
        "    y_b = min(box_a[3], box_b[3])\n",
        "\n",
        "    # Compute the area of intersection rectangle\n",
        "    inter_area = max(0, x_b - x_a + 1) * max(0, y_b - y_a + 1)\n",
        "\n",
        "    # Compute the area of both the prediction and tracker\n",
        "    # rectangles\n",
        "    box_a_area = (box_a[2] - box_a[0] + 1) * (box_a[3] - box_a[1] + 1)\n",
        "    box_b_area = (box_b[2] - box_b[0] + 1) * (box_b[3] - box_b[1] + 1)\n",
        "\n",
        "    # Compute the intersection over union by taking the intersection\n",
        "    # area and dividing it by the sum of prediction + tracker\n",
        "    # areas - the interesection area\n",
        "    iou = inter_area / float(box_a_area + box_b_area - inter_area)\n",
        "\n",
        "    # Since 0 <= IoU <= 1, we define 1/IoU as a distance.\n",
        "    # Distance values will be in [1, inf)\n",
        "    return 1 / iou if iou else (MAX_DISTANCE)\n",
        "\n",
        "\n",
        "def yolo_detections_to_norfair_detections(\n",
        "    yolo_detections: torch.tensor,\n",
        "    track_points: str = \"centroid\"  # bbox or centroid\n",
        ") -> List[Detection]:\n",
        "    \"\"\"convert detections_as_xywh to norfair detections\n",
        "    \"\"\"\n",
        "    norfair_detections: List[Detection] = []\n",
        "\n",
        "    if track_points == \"centroid\":\n",
        "        detections_as_xywh = yolo_detections.xywh[0]\n",
        "        for detection_as_xywh in detections_as_xywh:\n",
        "            centroid = np.array(\n",
        "                [\n",
        "                    detection_as_xywh[0].item(),\n",
        "                    detection_as_xywh[1].item()\n",
        "                ]\n",
        "            )\n",
        "            scores = np.array([detection_as_xywh[4].item()])\n",
        "            norfair_detections.append(\n",
        "                Detection(points=centroid, scores=scores)\n",
        "            )\n",
        "    elif track_points == \"bbox\":\n",
        "        detections_as_xyxy = yolo_detections.xyxy[0]\n",
        "\n",
        "        for detection_as_xyxy in detections_as_xyxy:\n",
        "            bbox = np.array(\n",
        "                [\n",
        "                    [detection_as_xyxy[0].item(), detection_as_xyxy[1].item()],\n",
        "                    [detection_as_xyxy[2].item(), detection_as_xyxy[3].item()]\n",
        "                ]\n",
        "            )\n",
        "            scores = np.array([detection_as_xyxy[4].item(), detection_as_xyxy[4].item()])\n",
        "            class_id = np.array(detection_as_xyxy[5])\n",
        "            norfair_detections.append(\n",
        "                Detection(points=bbox, scores=scores, label=yolo_detections.names[int(class_id)])\n",
        "            )\n",
        "\n",
        "    return norfair_detections\n",
        "\n",
        "\n",
        "model = YOLO(\"yolov5m6.pt\", device=None)\n",
        "\n",
        "input_path = \"/content/MOT17-04-DPM-raw.mp4\"\n",
        "\n",
        "video = Video(input_path=input_path)\n",
        "\n",
        "distance_function = iou\n",
        "distance_threshold = (DISTANCE_THRESHOLD_BBOX)\n",
        "\n",
        "tracker = Tracker(\n",
        "    distance_function=distance_function,\n",
        "    distance_threshold=distance_threshold,\n",
        ")\n",
        "paths_drawer = Paths(center, attenuation=0.01)\n",
        "\n",
        "for frame in video:\n",
        "    yolo_detections = model(frame)\n",
        "    detections = yolo_detections_to_norfair_detections(yolo_detections, track_points=\"bbox\")\n",
        "    tracked_objects = tracker.update(detections=detections)\n",
        "    norfair.draw_boxes(frame, detections, draw_labels=True)\n",
        "    norfair.draw_tracked_boxes(frame, tracked_objects)\n",
        "    frame = paths_drawer.draw(frame, tracked_objects)\n",
        "    video.write(frame)"
      ],
      "metadata": {
        "id": "I68NMpqDEvaV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fdba5c52-91bf-4c50-829f-7e6e9c1eaf02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<rich.jupyter.JupyterRenderable at 0x7f73f0493e90>"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">MOT17-04-DPM-raw.mp4 <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> <span style=\"color: #808000; text-decoration-color: #808000\">1.04fps</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<rich.jupyter.JupyterRenderable at 0x7f73ebd5ae10>"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Output video file saved to: ./MOT17-04-DPM-raw_out.mp4</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ffmpeg "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIWL02SbYFAK",
        "outputId": "bedecb13-5ec3-4808-a160-c09cfd32cae3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6084 sha256=f54407cf3b0dc4cca439907723aa384197cf56112c94fc21132eccd307aa215e\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/80/6e/caa3e16deb0267c3cbfd36862058a724144e19fdb9eb03af0f\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg\n",
            "Successfully installed ffmpeg-1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import Video\n",
        "Video('/content/MOT17-04-DPM-raw_out.mp4') "
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/content/MOT17-04-DPM-raw_out.mp4": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": "Not Found"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "6itX5DnaiRKX",
        "outputId": "94197c65-36a7-4b97-ec0e-41830a714f42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Video object>"
            ],
            "text/html": [
              "<video src=\"/content/MOT17-04-DPM-raw_out.mp4\" controls>\n",
              "      Your browser does not support the <code>video</code> element.\n",
              "    </video>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YTlM5OcDMo38"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}