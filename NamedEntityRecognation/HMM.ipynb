{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-w4Bm3pFTPF6",
        "outputId": "5e74e1fd-2308-4a3e-fea0-d431a27aa338"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install patool"
      ],
      "metadata": {
        "id": "zlePtEihT5n3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NrRuJE-cSe4N"
      },
      "outputs": [],
      "source": [
        "# import patoolib\n",
        "# patoolib.extract_archive(\"/content/drive/MyDrive/Dataset/NER_Dataset.rar\", \n",
        "#                          outdir=\"/content/drive/MyDrive/Dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ntC2dSbmSe4P"
      },
      "outputs": [],
      "source": [
        "def conll_sentences(conll_file):\n",
        "    sent = []\n",
        "    pos = []\n",
        "    chunk = []\n",
        "    entity = []\n",
        "    temp_sent = []\n",
        "    temp_pos = []\n",
        "    temp_chunk = []\n",
        "    temp_entity = []\n",
        "    \n",
        "    with open(conll_file) as f:\n",
        "        conll_raw_data = f.readlines()\n",
        "    conll_raw_data = [x.strip() for x in conll_raw_data]\n",
        "\n",
        "    for line in conll_raw_data:\n",
        "        if line != '':\n",
        "            split_line = line.split()\n",
        "            if len(split_line) == 4:\n",
        "                if split_line[0] != '-DOCSTART-':\n",
        "                    temp_sent.append(split_line[0])\n",
        "                    temp_pos.append(split_line[1])\n",
        "                    temp_chunk.append(split_line[2])\n",
        "                    \n",
        "                    # Rename entity values as PER, LOC, ORG, MISC, O\n",
        "                    old_ent = split_line[3]\n",
        "                    if old_ent in ('I-ORG', 'B-ORG'):\n",
        "                        new_ent = 'ORG'\n",
        "                    elif old_ent in ('I-LOC', 'B-LOC'):\n",
        "                        new_ent = 'LOC'\n",
        "                    elif old_ent in ('I-MISC', 'B-MISC'):\n",
        "                        new_ent = 'MISC'\n",
        "                    elif old_ent in ('I-PER', 'B-PER'):\n",
        "                        new_ent = 'PER'\n",
        "                    else:\n",
        "                        new_ent = 'O'\n",
        "                    temp_entity.append(new_ent)\n",
        "            else:\n",
        "                raise IndexError('Line split length does not equal 4.')\n",
        "        else:\n",
        "            if len(temp_sent) > 0:\n",
        "                assert(len(sent) == len(pos))\n",
        "                assert(len(sent) == len(chunk))\n",
        "                assert(len(sent) == len(entity))\n",
        "                sent.append(temp_sent)\n",
        "                pos.append(temp_pos)\n",
        "                chunk.append(temp_chunk)\n",
        "                entity.append(temp_entity)\n",
        "                temp_sent = []\n",
        "                temp_pos = []\n",
        "                temp_chunk = []\n",
        "                temp_entity = []\n",
        "    \n",
        "    return sent, pos, chunk, entity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6dVlmcPFSe4U"
      },
      "outputs": [],
      "source": [
        "def conll_words(conll_file):\n",
        "    all_words = []\n",
        "    all_pos = []\n",
        "    all_chunk = []\n",
        "    all_entities = []\n",
        "    \n",
        "    sent, pos, chunk, entity = conll_sentences(conll_file)\n",
        "\n",
        "    for se in sent:\n",
        "        for w in se:\n",
        "            all_words.append(w)\n",
        "    for po in pos:\n",
        "        for p in po:\n",
        "            all_pos.append(p)\n",
        "    for ch in chunk:\n",
        "        for c in ch:\n",
        "            all_chunk.append(c)\n",
        "    for en in entity:\n",
        "        for e in en:\n",
        "            all_entities.append(e)\n",
        "            \n",
        "    return all_words, all_pos, all_chunk, all_entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBR3y6UaSe4X"
      },
      "source": [
        "### CoNLL dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QglU0QikSe4b"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3hw57WSJSe4d"
      },
      "outputs": [],
      "source": [
        "train_file = r\"/content/drive/MyDrive/Dataset/NER_Dataset/CoNLL2003/eng.train\"\n",
        "testa_file = r\"/content/drive/MyDrive/Dataset/NER_Dataset/CoNLL2003/eng.testa\"\n",
        "testb_file = r\"/content/drive/MyDrive/Dataset/NER_Dataset/CoNLL2003/eng.testb\"\n",
        "testc_file = r\"/content/drive/MyDrive/Dataset/NER_Dataset/CoNLL2003/eng.testc\"\n",
        "\n",
        "train_words, _, _, train_entities = conll_words(train_file)\n",
        "testa_words, _, _, testa_entities = conll_words(testa_file)\n",
        "testb_words, _, _, testb_entities = conll_words(testb_file)\n",
        "testc_words, _, _, testc_entities = conll_words(testc_file)\n",
        "\n",
        "test_words = testa_words + testb_words + testc_words\n",
        "test_entities = testa_entities + testb_entities + testc_entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7tccj2CwSe4e"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kgahex3dSe4f"
      },
      "outputs": [],
      "source": [
        "combined_words = train_words + testa_words + testb_words + testc_words\n",
        "entity_set = set(train_entities + testa_entities + testb_entities + testc_entities)\n",
        "\n",
        "word_set = set()\n",
        "\n",
        "for line in combined_words:\n",
        "    for word in line:\n",
        "        word_set.add(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeDDWJjxSe4h",
        "outputId": "67325361-29ff-47a3-8d32-48be600a5a1b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'LOC', 'MISC', 'O', 'ORG', 'PER'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "entity_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTHxBGUCSe4j",
        "outputId": "aac96e23-edee-4981-918e-fb22cde88ba0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 0 logprob -5763881.357550944\n",
            "iteration 1 logprob -4430261.852424948\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "iterations = 2\n",
        "\n",
        "trainer = nltk.tag.hmm.HiddenMarkovModelTrainer(states=entity_set, symbols=word_set)\n",
        "\n",
        "model = trainer.train_unsupervised(train_words, max_iterations=iterations)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "HHcJCgRYSe4k"
      },
      "outputs": [],
      "source": [
        "test_result = model.tag(test_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dl78gEgVSe4k",
        "outputId": "23de60ec-efdd-4473-cd87-5289e687b7cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('CRICKET', 'ORG'),\n",
              " ('-', 'ORG'),\n",
              " ('LEICESTERSHIRE', 'ORG'),\n",
              " ('TAKE', 'ORG'),\n",
              " ('OVER', 'ORG'),\n",
              " ('AT', 'ORG'),\n",
              " ('TOP', 'ORG'),\n",
              " ('AFTER', 'ORG'),\n",
              " ('INNINGS', 'ORG'),\n",
              " ('VICTORY', 'ORG')]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "test_result[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_predicted = []\n",
        "\n",
        "for word, entity in test_result:\n",
        "  test_predicted.append(entity)"
      ],
      "metadata": {
        "id": "QMXlplBzVzy-"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy (expected, predicted):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for i in range(len(expected)):\n",
        "        total += 1\n",
        "        if (expected[i] == predicted[i]):\n",
        "            correct += 1\n",
        "    print('accuracy = %d / %d = %lf' % (correct, total, correct/total))"
      ],
      "metadata": {
        "id": "tjUNN30BbhfF"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy(test_entities, test_predicted)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTNOFWJBbxxq",
        "outputId": "b6843aea-8aef-4268-a763-bf1006f04693"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy = 4590 / 97832 = 0.046917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(test_entities, test_predicted))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81jJ6MCrbx43",
        "outputId": "81e3ad6b-e82f-4120-836a-8ce34336314d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.00      0.00      0.00      4019\n",
            "        MISC       0.00      0.00      0.00      2188\n",
            "           O       0.00      0.00      0.00     81111\n",
            "         ORG       0.05      1.00      0.09      4590\n",
            "         PER       0.00      0.00      0.00      5924\n",
            "\n",
            "    accuracy                           0.05     97832\n",
            "   macro avg       0.01      0.20      0.02     97832\n",
            "weighted avg       0.00      0.05      0.00     97832\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def entity_count (expected):\n",
        "\n",
        "    n_org = 0\n",
        "    n_per = 0\n",
        "    n_loc = 0\n",
        "    n_misc = 0\n",
        "    n_o = 0\n",
        "    \n",
        "    for e in expected:\n",
        "        if e == 'ORG':\n",
        "            n_org = n_org + 1\n",
        "        elif e == 'PER':\n",
        "            n_per = n_per + 1\n",
        "        elif e == 'LOC':\n",
        "            n_loc = n_loc + 1\n",
        "        elif e == 'MISC':\n",
        "            n_misc = n_misc + 1\n",
        "        elif e == 'O':\n",
        "            n_o = n_o + 1\n",
        "    \n",
        "    print('ORG:', n_org)\n",
        "    print('PER:', n_per)\n",
        "    print('LOC:', n_loc)\n",
        "    print('MISC:', n_misc)\n",
        "    print('O:', n_o)"
      ],
      "metadata": {
        "id": "i8lqcv1FcAbI"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entity_count(test_entities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fckOrewbb8ql",
        "outputId": "9f6d3df9-eae9-4854-9389-a8c06ea3ddac"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORG: 4590\n",
            "PER: 5924\n",
            "LOC: 4019\n",
            "MISC: 2188\n",
            "O: 81111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iodvOYUicrqm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "HMM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}